/*
 * MPI_Poisson.c
 * 2D Poison equation solver
 */

#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#include <time.h>
#include <mpi.h>  
#include <sys/stat.h> 
#include <sys/types.h> 

#define DEBUG 0

#define max(a,b) ((a)>(b)?a:b)

enum
{
  X_DIR, Y_DIR
};

/* global variables */
int gridsize[2];
double precision_goal;		/* precision_goal of solution */
int max_iter;			    /* maximum number of iterations alowed */

double omega = 1.95;		/* relaxation factor for SOR */

/* process specific variables */
int proc_rank;                     /* rank of current process */
int proc_coord[2];                 /* coordinates of current process in processgrid */
int proc_top, proc_right, proc_bottom, proc_left; /* ranks of neighboring procs */

/* non process specific variables */
int P;                             /* total number of processes */
int P_grid[2];                     /* process grid dimensions */
MPI_Comm grid_comm;                /* grid COMMUNICATOR */
MPI_Status status;

/* benchmark related variables */
clock_t ticks;			/* number of systemticks */
double wtime;            /* wall clock time */
int timer_on = 0;		/* is timer running? */
double comm_time = 0.0; /* Time spent in Exchange_Borders */
double calc_time = 0.0; /* Time spent in Do_Step */

/* local grid related variables */
double **phi;			/* grid */
int **source;			/* TRUE if subgrid element is a source */
int dim[2];			    /* grid dimensions */
int offset[2];		    /* coordinates of first local point in global grid */
MPI_Datatype border_type[2]; 

void Setup_Grid();
double Do_Step(int parity);
void Solve();
void Write_Grid();
void Clean_Up();
void Debug(char *mesg, int terminate);
void start_timer();
void resume_timer();
void stop_timer();
void print_timer();

void start_timer()
{
  if (!timer_on)
  {
    MPI_Barrier(grid_comm);  /* Synchronize all processes */
    ticks = clock();
    wtime = MPI_Wtime();          /* Record wall-clock time */
    timer_on = 1;
  }
}

void resume_timer()
{
  if (!timer_on)
  {
    ticks = clock() - ticks;
    wtime = MPI_Wtime() - wtime;
    timer_on = 1;
  }
}

void stop_timer()
{
  if (timer_on)
  {
    ticks = clock() - ticks;
    wtime = MPI_Wtime() - wtime;
    timer_on = 0;
  }
}

void print_timer()
{
  if (timer_on)
  {
    stop_timer();
    printf("(%i) Elapsed Wtime %14.6f s (%5.1f%% CPU)\n",
           proc_rank, wtime, 100.0 * ticks * (1.0 / CLOCKS_PER_SEC) / wtime);
    resume_timer();
  }
  else
    printf("(%i) Elapsed Wtime %14.6f s (%5.1f%% CPU)\n",
           proc_rank, wtime, 100.0 * ticks * (1.0 / CLOCKS_PER_SEC) / wtime);
}

void Debug(char *mesg, int terminate)
{
  if (DEBUG || terminate)
    printf("%s\n", mesg);
  if (terminate)
    exit(1);
}

void Setup_Grid()
{
  int x, y, s;
  double source_x, source_y, source_val;
  FILE *f;
  int upper_offset[2];

  Debug("Setup_Subgrid", 0);
  if (proc_rank==0)  /* Only the master process reads the input file */
  {
    f = fopen("input.dat", "r");
    if (f == NULL)
        Debug("Error opening input.dat", 1);
    fscanf(f, "nx: %i\n", &gridsize[X_DIR]);
    fscanf(f, "ny: %i\n", &gridsize[Y_DIR]);
    fscanf(f, "precision goal: %lf\n", &precision_goal);
    fscanf(f, "max iterations: %i\n", &max_iter);
  }

  MPI_Bcast(gridsize, 2, MPI_INT, 0, grid_comm);
  MPI_Bcast(&precision_goal, 1, MPI_DOUBLE, 0, grid_comm);
  MPI_Bcast(&max_iter, 1, MPI_INT, 0, grid_comm);

  /* Calculate dimensions of local subgrid */

  /* Calculate top left corner coordinates of local grid */
  offset[X_DIR] = gridsize[X_DIR] * proc_coord[X_DIR] / P_grid[X_DIR];
  offset[Y_DIR] = gridsize[Y_DIR] * proc_coord[Y_DIR] / P_grid[Y_DIR];

  /* Calculate bottom right corner coordinates */
  upper_offset[X_DIR] = gridsize[X_DIR] * (proc_coord[X_DIR] + 1) / P_grid[X_DIR];
  upper_offset[Y_DIR] = gridsize[Y_DIR] * (proc_coord[Y_DIR] + 1) / P_grid[Y_DIR];

  /* Calculate dimensions of local grid */
  dim[Y_DIR] = upper_offset[Y_DIR] - offset[Y_DIR];
  dim[X_DIR] = upper_offset[X_DIR] - offset[X_DIR];

  /* Add space for rows/columns of neighboring grid */
  dim[Y_DIR] += 2;
  dim[X_DIR] += 2;

  /* allocate memory */
  if ((phi = malloc(dim[X_DIR] * sizeof(*phi))) == NULL)
    Debug("Setup_Subgrid : malloc(phi) failed", 1);
  if ((source = malloc(dim[X_DIR] * sizeof(*source))) == NULL)
    Debug("Setup_Subgrid : malloc(source) failed", 1);
  if ((phi[0] = malloc(dim[Y_DIR] * dim[X_DIR] * sizeof(**phi))) == NULL)
    Debug("Setup_Subgrid : malloc(*phi) failed", 1);
  if ((source[0] = malloc(dim[Y_DIR] * dim[X_DIR] * sizeof(**source))) == NULL)
    Debug("Setup_Subgrid : malloc(*source) failed", 1);
  for (x = 1; x < dim[X_DIR]; x++)
  {
    phi[x] = phi[0] + x * dim[Y_DIR];
    source[x] = source[0] + x * dim[Y_DIR];
  }

  /* set all values to '0' */
  for (x = 0; x < dim[X_DIR]; x++)
    for (y = 0; y < dim[Y_DIR]; y++)
    {
      phi[x][y] = 0.0;
      source[x][y] = 0;
    }

  /* put sources in field */
  do
  {
    if (proc_rank==0)  /* Only the master process reads the source information */
        s = fscanf(f, "source: %lf %lf %lf\n", &source_x, &source_y, &source_val);
    MPI_Bcast(&s, 1, MPI_INT, 0, grid_comm);
    if (s==3)
    {
      MPI_Bcast(&source_x, 1, MPI_DOUBLE, 0, grid_comm);
      MPI_Bcast(&source_y, 1, MPI_DOUBLE, 0, grid_comm);
      MPI_Bcast(&source_val, 1, MPI_DOUBLE, 0, grid_comm);
      x = source_x * gridsize[X_DIR];
      y = source_y * gridsize[Y_DIR];
      x += 1;
      y += 1;

      /* Convert global index to local index */
      x = x - offset[X_DIR];
      y = y - offset[Y_DIR];

      /* Check if point belongs to this process */
      if (x > 0 && x < dim[X_DIR] - 1 && y > 0 && y < dim[Y_DIR] - 1)
      {
        phi[x][y] = source_val;
        source[x][y] = 1;
      }
    }
  }
  while (s==3);
  if (proc_rank == 0)
    fclose(f);
}

double Do_Step(int parity)
{
  int x, y;
  double old_phi;
  double max_err = 0.0;
  int start_y;
  int global_x, global_y_start;
  double t_start = MPI_Wtime(); // START TIMER

  /* calculate interior of grid */
  for (x = 1; x < dim[X_DIR] - 1; x++)
  {
      // Calculate global coordinates for the first element (y=1)
      global_x = x + offset[X_DIR];
      global_y_start = 1 + offset[Y_DIR];

      // Determine where to start: y=1 or y=2?
      // If the first element's parity matches our target, start at 1.
      // Otherwise, start at 2.
      if ((global_x + global_y_start) % 2 == parity) {
          start_y = 1;
      } else {
          start_y = 2;
      }

      // Strided Loop: Increment y by 2 to skip the 'if' check entirely
      for (y = start_y; y < dim[Y_DIR] - 1; y += 2)
      {
          // We still need to check if it's a source, but the parity check is gone!
          if (source[x][y] != 1)
          {
            old_phi = phi[x][y];
            double val_GS = (phi[x + 1][y] + phi[x - 1][y] +
                     phi[x][y + 1] + phi[x][y - 1]) * 0.25;
            phi[x][y] = old_phi + omega * (val_GS - old_phi);
            
            if (max_err < fabs(old_phi - phi[x][y]))
                max_err = fabs(old_phi - phi[x][y]);
          }
      }
  }
  calc_time += (MPI_Wtime() - t_start); // STOP & ACCUMULATE TIMER

  return max_err;
}

void Exchange_Borders()
{
  double t_start = MPI_Wtime(); // START TIMER
  Debug("Exchange_Borders", 0);

  /* Communication with X-Direction Neighbors (Left/Right in grid, but rows in memory) */
  MPI_Sendrecv(&phi[1][1], 1, border_type[X_DIR], proc_top, 0,
               &phi[0][1], 1, border_type[X_DIR], proc_top, 0,
               grid_comm, &status);

  MPI_Sendrecv(&phi[dim[X_DIR] - 2][1], 1, border_type[X_DIR], proc_bottom, 0,
               &phi[dim[X_DIR] - 1][1], 1, border_type[X_DIR], proc_bottom, 0,
               grid_comm, &status);
  
  /* Communication with Y-Direction Neighbors (Top/Bottom in grid, cols in memory) */
  MPI_Sendrecv(&phi[1][1], 1, border_type[Y_DIR], proc_left, 0,
               &phi[1][0], 1, border_type[Y_DIR], proc_left, 0,
               grid_comm, &status);

  MPI_Sendrecv(&phi[1][dim[Y_DIR] - 2], 1, border_type[Y_DIR], proc_right, 0,
               &phi[1][dim[Y_DIR] - 1], 1, border_type[Y_DIR], proc_right, 0,
               grid_comm, &status);

  comm_time += (MPI_Wtime() - t_start); // STOP & ACCUMULATE TIMER
}

void Solve()
{
  int count = 0;
  double delta;
  double global_delta;
  double delta1, delta2;

  Debug("Solve", 0);

  /* give global_delta a higher value then precision_goal */
  global_delta = 2 * precision_goal;

  while (count < max_iter)
  {
    Debug("Do_Step 0", 0);
    delta1 = Do_Step(0);
    Exchange_Borders();

    Debug("Do_Step 1", 0);
    delta2 = Do_Step(1);
    Exchange_Borders();

    delta = max(delta1, delta2);

    /* Calculate global max error */
    MPI_Allreduce(&delta, &global_delta, 1, MPI_DOUBLE, MPI_MAX, grid_comm);

    count++;

    if (count % 100 == 0 && proc_rank == 0) {
        printf("ERROR_LOG %d %e\n", count, global_delta);
    }
  }
  printf("(%i) Number of iterations : %i\n", proc_rank, count);
  // This prints the specific format your bash script is looking for: "RESULT <N> <CALC> <COMM>"
  if (proc_rank == 0) {
      printf("RESULT %d %f %f\n", gridsize[X_DIR], calc_time, comm_time);
  }
}

void Write_Grid()
{
  int x, y;
  FILE *f;
  char filename[40];

  Debug("Write_Grid", 0);

  /* Rank 0 handles directory creation */
  if (proc_rank == 0) {
      struct stat st = {0};
      if (stat("data", &st) == -1) {
          mkdir("data", 0700);
      }
  }

  /* Ensure all processes wait until directory is created */
  MPI_Barrier(grid_comm);

    /* Create a rank-dependent filename */
  sprintf(filename, "data/output%i.dat", proc_rank);

  if ((f = fopen(filename, "w")) == NULL)  
    Debug("Write_Grid fopen failed", 1);


  /* Loop over local grid (excluding ghost layers) */
  for (x = 1; x < dim[X_DIR] - 1; x++)
    for (y = 1; y < dim[Y_DIR] - 1; y++)
    //   fprintf(f, "%i %i %f\n", x, y, phi[x][y]);
      /* Write global coordinates by adding the offset */
      fprintf(f, "%i %i %f\n", 
              x + offset[X_DIR], 
              y + offset[Y_DIR], 
              phi[x][y]);
  fclose(f);
}



void Clean_Up()
{
  Debug("Clean_Up", 0);

  /* Free the MPI derived datatypes */
  MPI_Type_free(&border_type[X_DIR]);
  MPI_Type_free(&border_type[Y_DIR]);

  free(phi[0]);
  free(phi);
  free(source[0]);
  free(source);

}

void Setup_Proc_Grid(int argc, char **argv)
{
  int wrap_around[2];
  int reorder;

  Debug("My_MPI_Init", 0);

  /* Retrieve the number of processes */
  MPI_Comm_size(MPI_COMM_WORLD, &P);

  /* Calculate the number of processes per column and per row for the grid */
  if (argc > 2)
  {
    P_grid[X_DIR] = atoi(argv[1]);
    P_grid[Y_DIR] = atoi(argv[2]);
    
    if (P_grid[X_DIR] * P_grid[Y_DIR] != P)
      Debug("ERROR Proces grid dimensions do not match with P ", 1);
  }
  else
    Debug("ERROR Wrong parameter input", 1);

  /* Create process topology (2D grid) */
  wrap_around[X_DIR] = 0;
  wrap_around[Y_DIR] = 0; /* do not connect first and last process */
  reorder = 1;            /* reorder process ranks */

  /* Create the Cartesian Communicator 'grid_comm' */
  MPI_Cart_create(MPI_COMM_WORLD, 2, P_grid, wrap_around, reorder, &grid_comm);

  /* Retrieve new rank and cartesian coordinates of this process */
  MPI_Comm_rank(grid_comm, &proc_rank);
  MPI_Cart_coords(grid_comm, proc_rank, 2, proc_coord);

  printf("(%i) (x,y)=(%i,%i)\n", proc_rank, proc_coord[X_DIR], proc_coord[Y_DIR]);

  /* calculate ranks of neighboring processes */
  /* Note: The shift direction depends on how X_DIR/Y_DIR are mapped. 
     Assuming X_DIR is dim 0 (rows) and Y_DIR is dim 1 (cols) */
     
/* calculate ranks of neighboring processes */
  
  /* CHANGE: X_DIR (0) is Rows (Vertical), so shift it to get Top/Bottom */
  MPI_Cart_shift(grid_comm, X_DIR, 1, &proc_top, &proc_bottom);

  /* CHANGE: Y_DIR (1) is Cols (Horizontal), so shift it to get Left/Right */
  MPI_Cart_shift(grid_comm, Y_DIR, 1, &proc_left, &proc_right);

  if (DEBUG)
    printf("(%i) top %i, right %i, bottom %i, left %i\n", proc_rank, proc_top,
           proc_right, proc_bottom, proc_left);
}


void Setup_MPI_Datatypes()
{
  Debug("Setup_MPI_Datatypes", 0);

  /* Datatype for vertical data exchange */
  MPI_Type_vector(dim[X_DIR] - 2, 1, dim[Y_DIR], MPI_DOUBLE, &border_type[Y_DIR]);
  MPI_Type_commit(&border_type[Y_DIR]);

  /* Datatype for horizontal data exchange (X_DIR) */ 
  MPI_Type_vector(dim[Y_DIR] - 2, 1, 1, MPI_DOUBLE, &border_type[X_DIR]);
  MPI_Type_commit(&border_type[X_DIR]);
}

int main(int argc, char **argv)
{

    MPI_Init(&argc, &argv);
    /* Replaces MPI_Comm_rank. Setup_Proc_Grid creates the grid_comm */
    Setup_Proc_Grid(argc, argv); 
    start_timer();

    Setup_Grid();
    Setup_MPI_Datatypes();

    Solve();

    Write_Grid();

    print_timer();

    Clean_Up();
    MPI_Finalize();

  return 0;
}